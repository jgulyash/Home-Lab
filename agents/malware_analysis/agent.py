"""
Malware Analysis Agent

This agent performs automated malware analysis including static and dynamic
analysis, and generates detection signatures.
"""

import os
import hashlib
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from dataclasses import dataclass, asdict
from openai import OpenAI

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class MalwareAnalysisResult:
    """Results from malware analysis"""
    sample_hash: str
    sample_name: str
    analysis_timestamp: datetime
    file_type: str
    file_size: int
    threat_level: str  # critical, high, medium, low, benign
    malware_family: Optional[str]
    static_analysis: Dict[str, Any]
    dynamic_analysis: Dict[str, Any]
    network_indicators: List[str]
    file_indicators: List[str]
    mitre_techniques: List[str]
    yara_rules: List[str]
    detection_rules: List[str]
    recommendations: List[str]

    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['analysis_timestamp'] = self.analysis_timestamp.isoformat()
        return data


class MalwareAnalysisAgent:
    """
    AI-powered malware analysis agent that performs automated
    static and dynamic analysis
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

        logger.info("Malware Analysis Agent initialized")

    def analyze_sample(self, sample_path: str) -> MalwareAnalysisResult:
        """
        Perform comprehensive malware analysis
        """
        logger.info(f"Analyzing malware sample: {sample_path}")

        # Calculate hash
        sample_hash = self._calculate_hash(sample_path)

        # Get file info
        file_size = os.path.getsize(sample_path) if os.path.exists(sample_path) else 0
        sample_name = os.path.basename(sample_path)

        # Static analysis
        static_results = self.static_analysis(sample_path)

        # Dynamic analysis (mock - in production, run in sandbox)
        dynamic_results = self.dynamic_analysis_mock(sample_path)

        # Extract indicators
        network_iocs = self._extract_network_indicators(static_results, dynamic_results)
        file_iocs = self._extract_file_indicators(static_results, dynamic_results)

        # LLM-powered analysis
        llm_analysis = self._llm_analyze_malware(
            static_results,
            dynamic_results,
            network_iocs,
            file_iocs
        )

        # Generate detection rules
        yara_rules = self._generate_yara_rules(sample_hash, static_results, llm_analysis)
        detection_rules = self._generate_detection_rules(llm_analysis)

        result = MalwareAnalysisResult(
            sample_hash=sample_hash,
            sample_name=sample_name,
            analysis_timestamp=datetime.now(),
            file_type=static_results.get('file_type', 'unknown'),
            file_size=file_size,
            threat_level=llm_analysis.get('threat_level', 'medium'),
            malware_family=llm_analysis.get('malware_family'),
            static_analysis=static_results,
            dynamic_analysis=dynamic_results,
            network_indicators=network_iocs,
            file_indicators=file_iocs,
            mitre_techniques=llm_analysis.get('mitre_techniques', []),
            yara_rules=yara_rules,
            detection_rules=detection_rules,
            recommendations=llm_analysis.get('recommendations', [])
        )

        # Save analysis report
        self._save_analysis_report(result)

        logger.info(f"Analysis completed for {sample_hash}")
        return result

    def _calculate_hash(self, file_path: str) -> str:
        """Calculate SHA256 hash of file"""
        try:
            if not os.path.exists(file_path):
                return "unknown_hash"

            sha256_hash = hashlib.sha256()
            with open(file_path, "rb") as f:
                for byte_block in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(byte_block)
            return sha256_hash.hexdigest()
        except Exception as e:
            logger.error(f"Hash calculation failed: {e}")
            return "error_calculating_hash"

    def static_analysis(self, sample_path: str) -> Dict[str, Any]:
        """
        Perform static analysis of malware sample
        """
        logger.info("Performing static analysis")

        results = {
            'file_type': 'PE32',  # Mock
            'entropy': 7.2,  # High entropy suggests packing/encryption
            'sections': [
                {'name': '.text', 'size': 16384, 'entropy': 6.8},
                {'name': '.data', 'size': 8192, 'entropy': 5.2},
                {'name': '.rsrc', 'size': 4096, 'entropy': 7.9}
            ],
            'imports': [
                'kernel32.dll::CreateProcessA',
                'kernel32.dll::VirtualAlloc',
                'ws2_32.dll::connect',
                'advapi32.dll::RegSetValueExA'
            ],
            'strings': [
                'http://malicious-c2.com/beacon',
                'encrypted_payload.bin',
                'admin123',
                'SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run'
            ],
            'suspicious_indicators': [
                'High entropy (possible packing)',
                'Network communication functions',
                'Registry persistence mechanism',
                'Process injection capabilities'
            ]
        }

        return results

    def dynamic_analysis_mock(self, sample_path: str) -> Dict[str, Any]:
        """
        Mock dynamic analysis (in production, run in sandbox)
        """
        logger.info("Performing dynamic analysis (mock)")

        results = {
            'execution_time': 30,  # seconds
            'processes_created': [
                {'name': 'svchost.exe', 'pid': 1234, 'suspicious': True}
            ],
            'network_connections': [
                {'protocol': 'TCP', 'destination': '192.0.2.100:443', 'status': 'ESTABLISHED'}
            ],
            'files_created': [
                'C:\\Users\\Public\\payload.exe',
                'C:\\Windows\\Temp\\temp_file.tmp'
            ],
            'registry_modifications': [
                'HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run\\Malware'
            ],
            'behaviors': [
                'Attempted to disable Windows Defender',
                'Created persistence mechanism',
                'Established C2 connection',
                'Attempted privilege escalation'
            ]
        }

        return results

    def _extract_network_indicators(
        self,
        static: Dict[str, Any],
        dynamic: Dict[str, Any]
    ) -> List[str]:
        """Extract network IOCs"""
        indicators = []

        # From static analysis
        for string in static.get('strings', []):
            if 'http://' in string or 'https://' in string:
                indicators.append(string)

        # From dynamic analysis
        for conn in dynamic.get('network_connections', []):
            indicators.append(conn.get('destination', ''))

        return list(set(indicators))

    def _extract_file_indicators(
        self,
        static: Dict[str, Any],
        dynamic: Dict[str, Any]
    ) -> List[str]:
        """Extract file IOCs"""
        indicators = []

        # From dynamic analysis
        indicators.extend(dynamic.get('files_created', []))

        return list(set(indicators))

    def _llm_analyze_malware(
        self,
        static: Dict[str, Any],
        dynamic: Dict[str, Any],
        network_iocs: List[str],
        file_iocs: List[str]
    ) -> Dict[str, Any]:
        """Use LLM to analyze malware behavior and classify"""

        prompt = f"""Analyze this malware sample and provide comprehensive assessment:

Static Analysis:
{json.dumps(static, indent=2)}

Dynamic Analysis:
{json.dumps(dynamic, indent=2)}

Network IOCs: {', '.join(network_iocs)}
File IOCs: {', '.join(file_iocs)}

Provide analysis in JSON format:
{{
  "threat_level": "critical/high/medium/low",
  "malware_family": "name or null",
  "malware_type": "trojan/ransomware/backdoor/etc",
  "capabilities": ["list", "of", "capabilities"],
  "mitre_techniques": ["T1547.001", "etc"],
  "attack_chain": "description of kill chain",
  "recommendations": ["remediation", "steps"]
}}"""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are an expert malware analyst with deep knowledge of malware families and MITRE ATT&CK."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                response_format={"type": "json_object"}
            )

            analysis = json.loads(response.choices[0].message.content)
            logger.info("LLM malware analysis completed")
            return analysis

        except Exception as e:
            logger.error(f"LLM analysis failed: {e}")
            return {
                'threat_level': 'medium',
                'malware_family': None,
                'malware_type': 'unknown',
                'capabilities': [],
                'mitre_techniques': [],
                'attack_chain': 'Analysis failed',
                'recommendations': ['Manual analysis required']
            }

    def _generate_yara_rules(
        self,
        sample_hash: str,
        static: Dict[str, Any],
        llm_analysis: Dict[str, Any]
    ) -> List[str]:
        """Generate YARA rules for detection"""

        # Simple YARA rule generation
        malware_family = llm_analysis.get('malware_family', 'Unknown')
        strings = static.get('strings', [])[:5]  # Top 5 strings

        rule = f"""rule {malware_family.replace(' ', '_')}_{sample_hash[:8]}
{{
    meta:
        description = "Detects {malware_family} malware"
        author = "AI Malware Analysis Agent"
        date = "{datetime.now().strftime('%Y-%m-%d')}"
        hash = "{sample_hash}"

    strings:"""

        for i, s in enumerate(strings):
            # Escape special characters
            escaped = s.replace('\\', '\\\\').replace('"', '\\"')
            rule += f'\n        $s{i} = "{escaped}"'

        rule += """

    condition:
        2 of ($s*)
}"""

        return [rule]

    def _generate_detection_rules(self, llm_analysis: Dict[str, Any]) -> List[str]:
        """Generate detection rules for SIEM"""

        rules = []

        # Generate Wazuh rule
        malware_type = llm_analysis.get('malware_type', 'malware')
        mitre_techniques = llm_analysis.get('mitre_techniques', [])

        wazuh_rule = {
            'rule_id': f'100{hash(malware_type) % 1000:03d}',
            'level': 12,
            'description': f'{malware_type.title()} behavior detected',
            'mitre': mitre_techniques,
            'groups': ['malware', malware_type]
        }

        rules.append(json.dumps(wazuh_rule, indent=2))

        return rules

    def _save_analysis_report(self, result: MalwareAnalysisResult) -> None:
        """Save malware analysis report"""
        try:
            report_dir = "/app/data/reports/malware"
            os.makedirs(report_dir, exist_ok=True)

            filename = f"{report_dir}/malware_analysis_{result.sample_hash[:8]}.json"
            with open(filename, 'w') as f:
                json.dump(result.to_dict(), f, indent=2)

            logger.info(f"Analysis report saved: {filename}")

            # Save YARA rules
            yara_dir = "/app/data/yara"
            os.makedirs(yara_dir, exist_ok=True)

            for i, rule in enumerate(result.yara_rules):
                rule_file = f"{yara_dir}/{result.sample_hash[:8]}_{i}.yar"
                with open(rule_file, 'w') as f:
                    f.write(rule)
                logger.info(f"YARA rule saved: {rule_file}")

        except Exception as e:
            logger.error(f"Failed to save analysis report: {e}")


def main():
    """Main execution"""
    agent = MalwareAnalysisAgent()

    # Analyze sample (mock path)
    result = agent.analyze_sample("/app/data/samples/malware_sample.exe")

    print("\n" + "="*80)
    print("MALWARE ANALYSIS COMPLETED")
    print(f"Sample: {result.sample_name}")
    print(f"Hash: {result.sample_hash}")
    print(f"Threat Level: {result.threat_level}")
    print(f"Malware Family: {result.malware_family}")
    print(f"MITRE Techniques: {', '.join(result.mitre_techniques)}")
    print(f"Network IOCs: {len(result.network_indicators)}")
    print(f"File IOCs: {len(result.file_indicators)}")
    print(f"YARA Rules Generated: {len(result.yara_rules)}")
    print(f"Detection Rules Generated: {len(result.detection_rules)}")
    print("="*80)


if __name__ == "__main__":
    main()
